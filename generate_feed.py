#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from bs4 import BeautifulSoup
from typing import Optional, Iterable, Tuple, Dict, Any
import sys

def text_or_none(tag) -> Optional[str]:
    return tag.get_text(strip=True) if tag and hasattr(tag, "get_text") else None

def first_text(*candidates) -> Optional[str]:
    for t in candidates:
        if t:
            return t
    return None

def iter_entries(soup: BeautifulSoup) -> Iterable:
    # ÙŠØ¯Ø¹Ù… RSS (item) ÙˆAtom (entry)
    entries = soup.find_all('item')
    if entries:
        return entries
    return soup.find_all('entry')

def extract_fields(item) -> Dict[str, Optional[str]]:
    # Ø­Ø§ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ ÙˆØ³ÙˆÙ… Google namespaceØŒ Ø«Ù… Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø§Ù…Ø© Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ±
    gid = item.find('g:id')
    plain_id = item.find('id')
    title = item.find('g:title') or item.find('title')
    link = item.find('g:link') or item.find('link')
    price = item.find('g:price') or item.find('price')
    availability = item.find('g:availability') or item.find('availability')
    image_link = item.find('g:image_link') or item.find('image_link') or item.find('image')
    description = item.find('g:description') or item.find('description')

    product_id = first_text(
        text_or_none(gid),
        text_or_none(plain_id),
        # fallback Ù…Ø³ØªÙ…Ø¯ Ù…Ù† Ø¹Ù†ÙˆØ§Ù†/Ø±Ø§Ø¨Ø· Ø¥Ù† Ø§Ø¶Ø·Ø±Ø±Ù†Ø§
        text_or_none(title),
        text_or_none(link),
    )

    return {
        "id": product_id,
        "title": text_or_none(title),
        "link": text_or_none(link),
        "price": text_or_none(price),
        "availability": text_or_none(availability),
        "image_link": text_or_none(image_link),
        "description": text_or_none(description),
    }

def generate_google_feed(xml_text: str) -> Tuple[list, list]:
    """
    ÙŠØ¹ÙŠØ¯ (records, skipped) Ø­ÙŠØ«:
    - records: Ø¹Ù†Ø§ØµØ± ØµØ§Ù„Ø­Ø© ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§
    - skipped: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªØ®Ø·ÙŠ Ù„ÙƒÙ„ Ø¹Ù†ØµØ± Ù„Ù… ÙŠÙ…Ù„Ùƒ id ØµØ§Ù„Ø­
    """
    soup = BeautifulSoup(xml_text, 'xml')  # Ø¶Ø±ÙˆØ±ÙŠ Ù…Ø¹ namespaces Ù…Ø«Ù„ g: [web:6][web:9]
    records = []
    skipped = []

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªØµØ±ÙŠØ­ namespace ÙÙŠ Ø§Ù„Ø¬Ø°Ø± ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØµØ­Ø© Ø§Ù„ÙÙŠØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…ØµØ¯Ø± [web:16][web:18]
    # Ù„ÙƒÙ† BeautifulSoup Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØªØ³Ø¬ÙŠÙ„ namespace Ø¨Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ "g:tag" [web:9]
    for idx, item in enumerate(iter_entries(soup), start=1):
        data = extract_fields(item)
        if not data["id"]:
            skipped.append(f"Entry #{idx} skipped: missing id (g:id/id/title/link).")
            continue
        records.append(data)

    return records, skipped

def main():
    # Ù…Ø«Ø§Ù„: Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ XML Ù…Ù† stdin ÙÙŠ CI Ø£Ùˆ Ù…Ù† Ù…Ù„Ù
    # xml_input = open('feed.xml', 'r', encoding='utf-8').read()
    xml_input = sys.stdin.read()

    print("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ ...")

    records, skipped = generate_google_feed(xml_input)

    # Ø§Ø·Ø¨Ø¹ Ù…Ù„Ø®ØµØ§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙŠÙÙÙŠØ¯ ÙÙŠ Ø§Ù„Ù€ CI
    print(f"âœ… Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(records)}")
    print(f"âš ï¸ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…ØªØ®Ø·Ø§Ø©: {len(skipped)}")
    for msg in skipped[:10]:
        print(" -", msg)

    # ØªØ§Ø¨Ø¹ Ø¨Ù…Ø§ ÙŠÙ„Ø²Ù…Ùƒ: ÙƒØªØ§Ø¨Ø© CSV/JSON Ø£Ùˆ Ø¨Ù†Ø§Ø¡ XML Ø¬Ø¯ÙŠØ¯ Ù„Ø±ÙØ¹Ù Ù„Ø§Ø­Ù‚
    # Ù‡Ù†Ø§ Ù…Ø«Ø§Ù„ Ø·Ø¨Ø§Ø¹Ø© Ù…Ø®ØªØµØ± Ù„ÙƒÙ„ Ø¹Ù†ØµØ±
    for r in records[:5]:
        print(f"[ID={r['id']}] title={r['title']} price={r['price']} availability={r['availability']}")

if __name__ == "__main__":
    main()
