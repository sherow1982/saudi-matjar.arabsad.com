#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import requests
from typing import Optional, Iterable, Tuple, Dict, List
from bs4 import BeautifulSoup
from xml.etree.ElementTree import Element, SubElement, ElementTree, register_namespace

# Ø¥Ø¹Ø¯Ø§Ø¯ namespace Ù„Ù€ Google Merchant
G_NS = "http://base.google.com/ns/1.0"
register_namespace('g', G_NS)  # ÙŠØ¶Ù…Ù† xmlns:g ÙÙŠ Ø§Ù„Ø¬Ø°Ø± Ø¹Ù†Ø¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© [web:26][web:70]

def read_input_xml() -> str:
    # 1) Ø¥Ù† ÙˆÙØ¬Ø¯ stdin ØºÙŠØ± ÙØ§Ø±Øº
    if not sys.stdin.isatty():
        data = sys.stdin.read()
        if data.strip():
            return data

    # 2) Ø¥Ù† ÙˆÙØ¬Ø¯ Ù…Ù„Ù feed.xml Ù…Ø­Ù„ÙŠ
    if os.path.exists("feed.xml"):
        with open("feed.xml", "r", encoding="utf-8") as f:
            return f.read()

    # 3) Ø¥Ù† ÙˆÙØ¬Ø¯ Ø±Ø§Ø¨Ø· Ø¹Ø¨Ø± Ù…ØªØºÙŠØ± Ø¨ÙŠØ¦ÙŠ
    feed_url = os.getenv("FEED_URL")
    if feed_url:
        resp = requests.get(feed_url, timeout=30)
        resp.raise_for_status()
        return resp.text

    raise RuntimeError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¯Ø®Ù„ XML. Ù…Ø±Ù‘Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¨Ø± stdin Ø£Ùˆ Ø¶Ø¹ feed.xml Ø£Ùˆ Ø§Ø¶Ø¨Ø· FEED_URL.")

def text_or_none(tag) -> Optional[str]:
    return tag.get_text(strip=True) if tag and hasattr(tag, "get_text") else None

def first_text(*candidates) -> Optional[str]:
    for t in candidates:
        if t:
            return t
    return None

def iter_entries(soup: BeautifulSoup) -> Iterable:
    # ÙŠØ¯Ø¹Ù… RSS (item) Ùˆ Atom (entry)
    items = soup.find_all('item')
    if items:
        return items
    return soup.find_all('entry')

def extract_fields(item) -> Dict[str, Optional[str]]:
    # Ø­Ù‚ÙˆÙ„ Google Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ø§Ù…Ø© [web:10][web:31]
    gid = item.find('g:id')
    plain_id = item.find('id')
    title = item.find('g:title') or item.find('title')
    link = item.find('g:link') or item.find('link')
    price = item.find('g:price') or item.find('price')
    availability = item.find('g:availability') or item.find('availability')
    image_link = item.find('g:image_link') or item.find('image_link') or item.find('image') or item.find('enclosure')
    description = item.find('g:description') or item.find('description') or item.find('summary')

    product_id = first_text(
        text_or_none(gid),
        text_or_none(plain_id),
        # fallback Ù…Ø³ØªÙ…Ø¯ Ù…Ù† Ø¹Ù†ÙˆØ§Ù†/Ø±Ø§Ø¨Ø· Ø¥Ù† Ø§Ø¶Ø·Ø±Ø±Ù†Ø§
        text_or_none(title),
        text_or_none(link),
    )

    return {
        "id": product_id,
        "title": text_or_none(title),
        "link": text_or_none(link),
        "price": text_or_none(price),
        "availability": text_or_none(availability),
        "image_link": text_or_none(image_link),
        "description": text_or_none(description),
    }

def generate_google_records(xml_text: str) -> Tuple[List[Dict[str, Optional[str]]], List[str]]:
    """
    ÙŠØ¹ÙŠØ¯ (records, skipped):
    - records: Ø¹Ù†Ø§ØµØ± ØµØ§Ù„Ø­Ø© ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§
    - skipped: Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªØ®Ø·ÙŠ Ù„ÙƒÙ„ Ø¹Ù†ØµØ± Ø¨Ù„Ø§ id
    """
    soup = BeautifulSoup(xml_text, 'xml')  # Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø§Ø³Ù…Ø§Ø¡ Ù…Ø«Ù„ g:id [web:6]
    records: List[Dict[str, Optional[str]]] = []
    skipped: List[str] = []

    for idx, item in enumerate(iter_entries(soup), start=1):
        data = extract_fields(item)
        if not data["id"]:
            skipped.append(f"Entry #{idx} skipped: missing id (g:id/id/title/link).")
            continue
        records.append(data)

    return records, skipped

def write_google_rss(records: List[Dict[str, Optional[str]]], out_path: str = "products-feed.xml") -> None:
    """
    ÙŠÙƒØªØ¨ Ù…Ù„Ù RSS 2.0 Ù…Ø¹ xmlns:gØŒ ÙˆÙŠÙ…Ù„Ø£ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆÙÙ‚ Google Product Feed Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© [web:16][web:33][web:31].
    """
    # Ø¬Ø°Ø± RSS Ù…Ø¹ namespace g
    rss = Element('rss', attrib={"version": "2.0"})
    # Ø¥Ø¯Ø±Ø§Ø¬ xmlns:g ÙŠØªÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ø¨Ø± register_namespace ÙˆØ§Ø³ØªØ¹Ù…Ø§Ù„ QName Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©ØŒ
    # Ù„ÙƒÙ† Ù‡Ù†Ø§ Ø³Ù†Ø¶Ø¹ ÙˆØ³ÙˆÙ… g: ÙƒØ¹Ù†Ø§ØµØ± Ø§Ø³Ù…Ù‡Ø§ Ø§Ù„Ù†ØµÙŠ "g:..." Ø¶Ù…Ù† Ø¨ÙŠØ¦Ø© Ø¥Ø®Ø±Ø§Ø¬ ElementTree.
    # Ø³Ù†Ø¨Ù†ÙŠ channel/items Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ Ù„Ù€ RSS 2.0 [web:16].

    channel = SubElement(rss, 'channel')
    SubElement(channel, 'title').text = "Products Feed"
    SubElement(channel, 'link').text = "https://example.com"
    SubElement(channel, 'description').text = "Auto-generated Google Products Feed"

    # Ù„ÙƒÙ„ recordØŒ Ø£Ù†Ø´Ø¦ item Ù…Ø¹ ÙˆØ³ÙˆÙ… g: Ù…Ø·Ù„ÙˆØ¨Ø©
    for rec in records:
        item = SubElement(channel, 'item')

        # Ø¹Ù†Ø§ØµØ± Google ØªÙÙƒØªØ¨ ÙƒØ¹Ù†Ø§ØµØ± Ø°Ø§Øª prefix g:
        # Ù…Ø¹ ElementTreeØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… "g:tag" ÙŠØ®Ø±Ø¬ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¥Ø°Ø§ namespace Ù…Ø³Ø¬Ù„ [web:26][web:70]
        def g(tag: str, value: Optional[str]):
            if value:
                SubElement(item, f"{{{G_NS}}}{tag}").text = value  # QName via {ns}tag [web:26][web:70]

        g('id', rec.get('id'))
        g('title', rec.get('title'))
        g('description', rec.get('description'))
        g('link', rec.get('link'))
        g('image_link', rec.get('image_link'))
        g('price', rec.get('price'))
        g('availability', rec.get('availability'))

        # Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù†ØµØ§Øª ØªØªÙˆÙ‚Ø¹ Ø£ÙŠØ¶Ø§Ù‹ <guid> Ø£Ùˆ <link> Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠÙŠÙ† ÙÙŠ RSS
        if rec.get('link'):
            SubElement(item, 'link').text = rec['link']
        if rec.get('id'):
            SubElement(item, 'guid').text = rec['id']

    # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„ØªØµØ±ÙŠØ­ Ùˆ UTF-8
    tree = ElementTree(rss)
    tree.write(out_path, encoding="utf-8", xml_declaration=True)

def main():
    print("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ ...")
    xml_input = read_input_xml()
    records, skipped = generate_google_records(xml_input)

    print(f"âœ… Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(records)}")
    print(f"âš ï¸ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…ØªØ®Ø·Ø§Ø©: {len(skipped)}")
    for msg in skipped[:10]:
        print(" -", msg)

    # ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù RSS Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    write_google_rss(records, "products-feed.xml")
    print("ğŸ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: products-feed.xml")

if __name__ == "__main__":
    main()
